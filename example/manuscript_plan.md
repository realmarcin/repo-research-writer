# Manuscript Plan: ProteinNet-Transformer Paper

**Target Journal**: Bioinformatics (Oxford Academic)
**Format**: Application Note
**Generated**: 2026-02-03

---

## Structure Overview

Following Bioinformatics journal guidelines:
1. Abstract (structured: Motivation, Results, Availability)
2. Introduction
3. Methods
4. Results
5. Discussion
6. Data Availability

---

## Section 1: Abstract

**Word Limit**: 250 words
**Structure**: Must use structured format with subsections

### Subsections:

**Motivation**
- Problem: Protein structure prediction remains computationally expensive
- Gap: Current methods (AlphaFold2) require significant compute resources
- Our approach: Transformer-based architecture with structure-aware encoding

**Results**
- Main finding: TM-score of 0.87 on CASP14 (12% improvement over AlphaFold2)
- Secondary: 3x faster training time (48 hours vs 144 hours)
- Interpretability: Attention heads correlate with biological contacts

**Availability**
- Code: GitHub repository (link)
- Data: Zenodo deposit (DOI)
- Model: Pre-trained weights available

### Supporting Files:
- `CLUEWRITE.md` (lines 15-25: Key Findings summary)
- `data/benchmark_results.csv` (for exact numbers)

---

## Section 2: Introduction

**Purpose**: Establish context and motivation
**Length**: ~600 words

### Content Flow:

1. **Background** (150 words)
   - Importance of protein structure prediction in biology
   - Historical context: experimental methods → computational prediction
   - Citation: [alphafold2021], [rosettafold2021]

2. **Current State** (200 words)
   - AlphaFold2 breakthrough and limitations
   - Computational cost barriers for academic labs
   - Need for faster, interpretable methods
   - Citation: [casp14]

3. **Our Contribution** (200 words)
   - ProteinNet-Transformer architecture
   - Novel structure-aware positional encoding
   - Attention mechanism for interpretability
   - Citation: [transformer2017]

4. **Paper Organization** (50 words)
   - Methods: architecture and training
   - Results: benchmark comparisons
   - Discussion: implications and future work

### Supporting Files:
- `CLUEWRITE.md` (lines 1-14: Project Overview)
- `references.bib` (all citations)

---

## Section 3: Methods

**Purpose**: Technical description enabling reproduction
**Length**: ~800 words

### Subsection 3.1: Model Architecture (300 words)

**Content**:
- Transformer encoder details (12 layers, 768 dim, 12 heads)
- Input representation: sequence + MSA features
- Output: 3D coordinates (Cα atoms)
- **Novel component**: Structure-aware positional encoding

**Supporting Files**:
- `scripts/train_model.py` (lines 18-50: `build_transformer()` function)
- `CLUEWRITE.md` (lines 110-116: Model Architecture notes)

**Key Technical Details to Extract**:
- Hidden dimension: 768
- Number of layers: 12
- Attention heads: 12
- Dropout rate: 0.1

### Subsection 3.2: Training Procedure (250 words)

**Content**:
- Dataset: 30,000 PDB structures (pre-2018)
- Loss function: RMSD + TM-score combination
- Optimizer: AdamW (lr=1e-4, weight_decay=0.01)
- Hardware: 4× NVIDIA A100 GPUs
- Training time: 48 hours

**Supporting Files**:
- `scripts/train_model.py` (lines 70-100: `train_epoch()` function)
- `CLUEWRITE.md` (lines 118-125: Training Details)

**Code References**:
```python
# Loss calculation from train_model.py:87-89
rmsd_loss = compute_rmsd(predictions, structures)
tm_loss = 1.0 - compute_tm_score(predictions, structures)
loss = 0.5 * rmsd_loss + 0.5 * tm_loss
```

### Subsection 3.3: Evaluation Protocol (250 words)

**Content**:
- Benchmark: CASP14 free modeling targets (52 proteins)
- Metrics: TM-score (primary), GDT-TS, RMSD
- Baselines: AlphaFold2, RoseTTAFold
- Statistical testing: Wilcoxon signed-rank test

**Supporting Files**:
- `scripts/evaluate.py` (lines 45-67: `compute_tm_score()`)
- `CLUEWRITE.md` (lines 127-132: Evaluation Protocol)

---

## Section 4: Results

**Purpose**: Present findings with evidence
**Length**: ~700 words

### Subsection 4.1: Benchmark Comparison (350 words)

**Main Claim**: ProteinNet-Transformer achieves mean TM-score of 0.87

**Evidence Chain**:
1. **Data Source**: `data/benchmark_results.csv`
2. **Verification**: Run `rrwrite-verify-stats.py --file data/benchmark_results.csv --col tm_score --op mean` filtered by model_name
3. **Expected Output**: 0.87 (ProteinNet-Transformer)
4. **Figure Reference**: Figure 1 (accuracy_comparison.png)

**Comparison Points**:
- AlphaFold2: 0.78 (verify from CSV)
- RoseTTAFold: 0.74 (verify from CSV)
- Improvement: 12% over AlphaFold2, 18% over RoseTTAFold

**Figure 1 Description**:
- **Generated by**: `scripts/evaluate.py` (line 89: `generate_comparison_plot()`)
- **Content**: Bar plot with error bars showing mean TM-scores
- **Caption**: "Comparison of structure prediction accuracy on CASP14 benchmark. ProteinNet-Transformer (green) achieves mean TM-score of 0.87, outperforming AlphaFold2 (blue, 0.78) and RoseTTAFold (red, 0.74). Error bars show standard deviation across 52 protein targets. *** indicates p < 0.001 (Wilcoxon signed-rank test)."

### Subsection 4.2: Training Efficiency (200 words)

**Claim**: 3x faster training (48 hours vs 144 hours for comparable models)

**Evidence**:
- File: `data/training_metrics.csv`
- Column: `convergence_time`
- Verification command: `--file data/training_metrics.csv --col convergence_time --op max`

**Figure 2 Reference**: training_curve.png

### Subsection 4.3: Interpretability (150 words)

**Claim**: 85% of attention heads correlate with biological contacts

**Evidence**:
- File: `data/attention_analysis.csv`
- Analysis: Count rows where `correlation_with_contacts > 0.7` and `p_value < 0.05`
- Supporting notebook: `notebooks/exploratory_analysis.ipynb` (Cell 12)

---

## Section 5: Discussion

**Purpose**: Interpret results and contextualize
**Length**: ~500 words

### Content Flow:

1. **Summary of Findings** (100 words)
   - Restate main results in context of field
   - Emphasis on practical implications

2. **Comparison with Prior Work** (150 words)
   - Why improvement over AlphaFold2 matters
   - Trade-offs: accuracy vs speed vs interpretability
   - Citation: [alphafold2021], [rosettafold2021]

3. **Biological Insights** (150 words)
   - Attention mechanism learning meaningful patterns
   - Implications for understanding protein folding
   - Potential for guiding experimental design

4. **Limitations** (50 words)
   - Performance on membrane proteins (lower accuracy)
   - Requires MSA features (computational overhead)

5. **Future Work** (50 words)
   - Extension to protein-protein interactions
   - Multi-chain complexes
   - Integration with experimental data

### Supporting Files:
- `CLUEWRITE.md` (lines 145-148: Notes for Manuscript)
- All prior sections for cross-referencing results

---

## Section 6: Data Availability

**Required by Journal**: Must include explicit data/code availability statements

### Statements:

**Software Availability**:
- Source code: https://github.com/username/proteinnet-transformer
- License: MIT
- Language: Python 3.9+
- Dependencies: Listed in requirements.txt

**Data Availability**:
- Training data: PDB structures (publicly available)
- Benchmark predictions: Zenodo deposit (DOI: 10.5281/zenodo.xxxxx)
- Preprocessed features: Available upon request

**Model Availability**:
- Pre-trained weights: Zenodo deposit (included with data)
- Inference script: Included in GitHub repository

### Supporting Files:
- `CLUEWRITE.md` (lines 145-148: Data availability notes)

---

## Verification Checklist

Before finalizing each section, verify:

- [ ] All numbers cross-referenced with source CSV files
- [ ] All figures mentioned have corresponding files in `figures/`
- [ ] All code references point to actual line numbers in scripts
- [ ] All citations exist in `references.bib`
- [ ] Word counts within Bioinformatics limits
- [ ] Structured abstract format followed
- [ ] Data availability statement complete

---

## File Mapping Summary

| Section | Primary Data Sources | Scripts | Figures |
|---------|---------------------|---------|---------|
| Abstract | benchmark_results.csv | - | - |
| Introduction | CLUEWRITE.md | - | - |
| Methods | CLUEWRITE.md | train_model.py, evaluate.py | - |
| Results | benchmark_results.csv, training_metrics.csv, attention_analysis.csv | evaluate.py | accuracy_comparison.png, training_curve.png |
| Discussion | All above | - | - |

---

**Next Steps**:
1. Use `/rrwrite-draft-section` skill to write each section in order
2. After each section, run `rrwrite-verify-stats.py` to check numerical claims
3. Use `/rrwrite-critique-manuscript` skill before final submission
